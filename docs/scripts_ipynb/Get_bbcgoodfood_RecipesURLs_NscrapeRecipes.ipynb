{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Scrape bbcgoodfood.com recipes' unique URLs from 'index' pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "## import modules\n",
    "# ---------------------------------------------------------------------\n",
    "# Python 2 & 3 Compatibility\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate generic list of index page urls for scraping recipe links/urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbcgf_urlpgList = ['http://www.bbcgoodfood.com/search/recipes?query=']\n",
    "\n",
    "R_host = 'http://www.bbcgoodfood.com/'\n",
    "path = '/search?query=&page='\n",
    "\n",
    "for p in range(1,672+1):\n",
    "# for p in range(216,217+1):\n",
    "    bbcgf_urlpgList.append((R_host + path + str(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slight tweak to by-pass website access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "cnt=0\n",
    "\n",
    "for pg in bbcgf_urlpgList:\n",
    "    pgResp = requests.get(pg, headers=headers)\n",
    "    \n",
    "    if cnt%10==0:\n",
    "        print(cnt)\n",
    "\n",
    "    if pgResp.status_code == 200:\n",
    "        soup = BeautifulSoup(pgResp.content, 'lxml')\n",
    "        \n",
    "        tmp = soup.find(\"div\",{\"class\":\"view-content\"}).find_all(\"article\",{\"class\":\"node node-recipe node-teaser-item clearfix\"})\n",
    "\n",
    "        if cnt==0:\n",
    "            Links = [link.a[\"href\"] for link in tmp]\n",
    "        elif cnt>0:\n",
    "            tmp2 = [link.a[\"href\"] for link in tmp]\n",
    "            Links.extend(tmp2)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(Links) #10081"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect recipe links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_links = pd.Series(Links, name='URL')\n",
    "# R_links = R_links[0].replace(['0'],'URL')\n",
    "R_links = R_links.to_frame()\n",
    "R_links.to_csv('BBCgoodfood_recipesURL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/recipes/4942/lemon-drizzle-cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/recipes/3228/chilli-con-carne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/recipes/3092/ultimate-chocolate-cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/recipes/1223/bestever-brownies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/recipes/3229/yummy-scrummy-carrot-cake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       URL\n",
       "0         /recipes/4942/lemon-drizzle-cake\n",
       "1           /recipes/3228/chilli-con-carne\n",
       "2    /recipes/3092/ultimate-chocolate-cake\n",
       "3          /recipes/1223/bestever-brownies\n",
       "4  /recipes/3229/yummy-scrummy-carrot-cake"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now use recipe links to get recipe info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "## import modules\n",
    "# ---------------------------------------------------------------------\n",
    "# Python 2 & 3 Compatibility\n",
    "# from __future__ import print_function, division\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "# import re\n",
    "# import time\n",
    "# import sys\n",
    "\n",
    "# credits: base recipe-scraper script with modification from https://github.com/hhursev/recipe-scraper\n",
    "# avoid reinventing the wheel....\n",
    "from recipe_scrapers import scrap_me \n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_links = pd.read_csv('BBCgoodfood_recipesURL.csv', index_col=[0] )\n",
    "# R_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrapeInt = [int(i) for i in np.round(np.linspace(0, 10081,100))]\n",
    "# scrapeInt = [int(i) for i in scrapeInt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_host = 'http://www.bbcgoodfood.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(100000) # else pickle would not pickle.... =S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folderpath='/Users/hrm/Documents/Dropbox/DSrelated/Metis/recipes/bbc_goodfood_recipes_pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrape_chunk_loop : 33\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "/Users/hrm/Documents/Dropbox/DSrelated/Metis/recipes/bbc_goodfood_recipes_pickles/scrapedInfo_BBCgdfd_3259to3360recipes.p\n"
     ]
    }
   ],
   "source": [
    "# for sI in range(33,34): #redo\n",
    "for sI in range(1,len(scrapeInt)):\n",
    "    print('scrape_chunk_loop : ' + format(sI) )\n",
    "\n",
    "    scrapedInfo =[]\n",
    "    cnt = 0\n",
    "    for n in R_links.URL[scrapeInt[sI-1] : scrapeInt[sI]]: #[:100]:\n",
    "\n",
    "        if cnt%10==0:\n",
    "            print(cnt)\n",
    "\n",
    "        tmp = scrap_me(R_host+n)\n",
    "        scrapedInfo.append(tmp)\n",
    "\n",
    "        cnt+=1\n",
    "\n",
    "    filename = (folderpath +\"scrapedInfo_BBCgdfd_\" + format(scrapeInt[sI-1] ) + \"to\" + format(scrapeInt[sI] ) + \"recipes.p\")\n",
    "    print(filename)\n",
    "    #pickle.dump(scrapedInfo, open( \"scrapedInfo_BBCgdfd_100recipes.p\", \"wb\" ) )    \n",
    "    #     pickle.dump(scrapedInfo, open( filename, \"wb\" ) ) \n",
    "    \n",
    "    with open( filename, \"wb\" ) as f:\n",
    "        pickle.dump(scrapedInfo,f,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = pickle.load(open( filename, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
